{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariolh33/G2_100472188_100429058/blob/main/Competicion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos desde github el modelo y los datos de competicion"
      ],
      "metadata": {
        "id": "SerigKk5SHNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrsNaRjrSkbZ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import gzip\n",
        "\n",
        "# URL del archivo CSV comprimido\n",
        "url_datos_competicion = 'https://github.com/Mariolh33/G2_100472188_100429058/raw/main/wind_comp.csv.gz'\n",
        "\n",
        "# Descargar el archivo CSV comprimido\n",
        "response = requests.get(url_datos_competicion)\n",
        "\n",
        "# Verificar si la descarga fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Descomprimir el archivo y cargarlo en un DataFrame\n",
        "    with gzip.open(BytesIO(response.content), 'rt') as file:\n",
        "        datos_competicion = pd.read_csv(file)\n",
        "else:\n",
        "    print(\"Error al descargar el archivo.\")\n",
        "\n",
        "# URL del archivo pkl\n",
        "url_modelo_final = 'https://github.com/Mariolh33/G2_100472188_100429058/raw/main/modelo_final.pkl'\n",
        "\n",
        "# Descargar el archivo pkl\n",
        "response_modelo = requests.get(url_modelo_final)\n",
        "\n",
        "# Verificar si la descarga fue exitosa\n",
        "if response_modelo.status_code == 200:\n",
        "    # Cargar el modelo desde el contenido descargado\n",
        "    modelo_entrenado = pickle.loads(response_modelo.content)\n",
        "else:\n",
        "    print(\"Error al descargar el archivo.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiamos los datos de competición de la misma forma que hicimos con los datos de entrenamiento anteriormente, de esta forma los datos de entreda seran los mismos con los que se entrenó el modelo."
      ],
      "metadata": {
        "id": "7HV7dUTxUk-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez limpios realizamos la predicción y procedemos a guardarlos en un archivo csv"
      ],
      "metadata": {
        "id": "Em9KMVXbUyKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Seleccionar las variables a mantener y eliminar\n",
        "variables_a_eliminar = {'lai_lv.13', 'v100.13', 'v10.13', 'u10.13'}\n",
        "columnas_a_mantener = ['datetime'] + [col for col in datos_competicion.columns if col.endswith('13') and col not in variables_a_eliminar]\n",
        "\n",
        "# Filtrar el DataFrame para mantener solo las columnas seleccionadas\n",
        "datos_finales = datos_competicion[columnas_a_mantener]\n",
        "\n",
        "\n",
        "\n",
        "# Seleccionar solo los datos de entrenamiento\n",
        "datos_finales = datos_finales.drop(['datetime'], axis=1)\n",
        "\n",
        "# Usar el modelo para hacer predicciones en el conjunto de datos de entrenamiento\n",
        "predicciones = modelo_entrenado.predict(datos_finales)\n",
        "\n",
        "# Convertir las predicciones a un DataFrame\n",
        "df_predicciones = pd.DataFrame(predicciones, columns=['Predicciones'])\n",
        "\n",
        "# Guardar las predicciones en un archivo CSV\n",
        "df_predicciones.to_csv('predicciones.csv', index=False)"
      ],
      "metadata": {
        "id": "CJ-WLP51W_15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}